

# 实验三 Spark机器学习

## 1. Spark-shell常⽤指令

### spark-shell

登录服务器，输入spark-shell

![image-20211116191522934](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211116191522934.png)

![image-20211116191602562](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211116191602562.png)

输入:help

![image-20211116193638357](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211116193638357.png)

使⽤:load打印Hello Word，注意这里path是相对地址

<img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211116193626034.png" alt="image-20211116193626034" style="zoom:50%;" />

## 2. 使用Spark进行词频统计

实验所用数据集为WMT16-newstest2016en.txt，首先将其传入Hadoop文件系统。

![image-20211117132936528](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117132936528.png)

进入spark- shell

![image-20211117133116430](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117133116430.png)

加载数据集

![image-20211117133202335](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117133202335.png)

查看第一行&查看行数

<img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117133225800.png" alt="image-20211117133225800" style="zoom:50%;" />

统计词频并保存

![image-20211117133349404](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117133349404.png)

打开保存后的hdfs文件，部分结果如下

<img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117141013564.png" alt="image-20211117141013564" style="zoom:50%;" />

### Bonus

为方便与其他词频统计函数对比，先记录map + reduceByKey方法的时间

![image-20211117151236128](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117151236128.png)

法1:使用countByValue代替map + reduceByKey

代码如下

```scala
import java.util.Date

val words = sc.textFile("/dsjxtjc/2021214316/newstest2016en.txt")
var t1 = new Date().getTime
val result = words.flatMap(l => l.split(" ")).countByValue()
var t2 = new Date().getTime
println(t2-t1)
```

实验结果：耗时713

![image-20211117151149440](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117151149440.png)

法二：方法四:groupByKey+map

```scala
import java.util.Date

val config: SparkConf = new SparkConf().setMaster("local[*]").setAppName("WordCount4")
val sc: SparkContext = new SparkContext(config)
val lines: RDD[String] = sc.textFile("/dsjxtjc/2021214316/newstest2016en.txt")
var t1 = new Date().getTime
val groupByKeyRDD: RDD[(String, Iterable[Int])] = lines.flatMap(_.split(" ")).map((_, 1)).groupByKey()
groupByKeyRDD.map(tuple => {
    (tuple._1, tuple._2.sum)
}).collect().foreach(println)
var t2 = new Date().getTime
println(t2-t1)
```

实验结果：耗时955

![image-20211117151938129](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117151938129.png)

## 3 使⽤Spark 计算均值与⽅差

使用的数据集与实验二相同，此处不再赘述生成方法。

将数据集上传到HDFS

![image-20211117152713691](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117152713691.png)

运⾏spark-shell, 从HDFS 加载number.txt：

![image-20211117152902935](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117152902935.png)

加载的数据为字符串形式，需要转成数值型，这⾥转double型：

![image-20211117152926040](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117152926040.png)

统计数字个数：

<img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117153038665.png" alt="image-20211117153038665" style="zoom:60%;" />

计算均值：

![image-20211117153118778](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117153118778.png)

计算方差：

![image-20211117153138978](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117153138978.png)

计算标准差：

<img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211117153206231.png" alt="image-20211117153206231" style="zoom:60%;" />

## 4 Spark 机器学习

本题实现了向量表示的2元线性回归。

1. 生成数据集

   每条数据记录包括三个浮点数，分别对应2个特征值和1个标签值，生成1000条记录。

   注：由于scala代码中直接从本地目录调用，无需先传入hadoop中。

   ```python
   with open('/Users/xueyuan/Desktop/dataset.txt', 'w') as f:
       for _ in range(1000):
           feature1 = random.random()
           feature2 = random.random()
           lb = 2*feature1 + feature2 + random.random()
           to_write = str(feature1)+' '+str(feature2)+','+str(lb)+'\n'
           f.write(to_write)
   f.close()
   ```

   ![image-20211128195454461](/Users/xueyuan/Library/Application Support/typora-user-images/image-20211128195454461.png)

2. 线性回归的scala实现

   建立矩阵类，实现矩阵间的运算，此处仅列出部分代码。

   ```scala
   		def +(a:Matrix):Matrix = {
           if(this.rownum != a.rownum || this.colnum != a.colnum){
               val data:ArrayBuffer[Double] = ArrayBuffer()
               return new Matrix(data.toArray,this.rownum)
           }else{
               val data:ArrayBuffer[Double] = ArrayBuffer()
               for(i <- 0 until this.rownum){
                   for(j <- 0 until this.colnum){
                       data += this.matrix(i)(j) + a.matrix(i)(j)
                   }
               }
               return new Matrix(data.toArray,this.rownum)
           }       
       }
   
       def -(a:Matrix):Matrix = {
           if(this.rownum != a.rownum || this.colnum != a.colnum){
               val data:ArrayBuffer[Double] = ArrayBuffer()
               return new Matrix(data.toArray,this.rownum)
           }else{
               val data:ArrayBuffer[Double] = ArrayBuffer()
               for(i <- 0 until this.rownum){
                   for(j <- 0 until this.colnum){
                       data += this.matrix(i)(j) - a.matrix(i)(j)
                   }
               }
               return new Matrix(data.toArray,this.rownum)
           }       
       }
   
   		def *(a:Matrix):Matrix = {
           if(this.colnum != a.rownum){
               val data:ArrayBuffer[Double] = ArrayBuffer()
               return new Matrix(data.toArray,this.rownum)
           }else{
               val data:ArrayBuffer[Double] = ArrayBuffer()
               for(i <- 0 until this.rownum){
                   for(j <- 0 until a.colnum){
                       var num = 0.0
                       for(k <- 0 until this.colnum){
                           num += this.matrix(i)(k) * a.matrix(k)(j)
                       }
                   data += num
                   }
               }
           return new Matrix(data.toArray,this.rownum)
           }
       }
   		def transpose():Matrix = {
           val transposeMatrix = for (i <- Array.range(0,colnum)) yield {
                for (rowArray <- this.matrix) yield rowArray(i)
               }
           return new Matrix(transposeMatrix.flatten,colnum)
       }
   ```

   线性回归实现代码

   ```scala
   var x = new Array[Double](3000)
   var y = new Array[Double](1000)
   
   val lines = Source.fromFile("/home/dsjxtjc/2021214316/EXP3/Task5/dataset.txt").getLines
   
   var i = 0 
   for (line <- lines){
       val tmpx =line.split(',')(0)
       y(i) = line.split(',')(1).toDouble
       for (j <- 0 to 2) 
           x(i*3+j) = tmpx(j).toDouble
       i = i + 1
   }
   
   var matX = new Matrix(x,1000)
   var matY = new Matrix(y,1000)
   val w = new Array[Double](3)
   var matW = new Matrix(w,3)
   
   val lr = 0.0000001
   val epoch = 50
   
   for (j <- 1 to epoch){
       val maty:Matrix = matX * matW - matY
       val g:Matrix = matX.transpose * maty
       val loss = maty.transpose * maty * (1.0 / (2 * 1000))
       matW = matW - g * lr
       println(loss)
   }
   ```

   在spark-shell中运行该脚本

   <img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211128202814186.png" alt="image-20211128202814186" style="zoom:50%;" />

   由于每次新建变量都会输出，此处省略初始化的变量，仅展示loss变化情况，可以看到是在迭代中不断下降的。

   <img src="/Users/xueyuan/Library/Application Support/typora-user-images/image-20211128203039407.png" alt="image-20211128203039407" style="zoom:50%;" />

​	
